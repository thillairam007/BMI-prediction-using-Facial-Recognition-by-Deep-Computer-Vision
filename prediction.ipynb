{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sklearn\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cassandra.cluster import Cluster\n",
    "# from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# cloud_config= {\n",
    "#   'secure_connect_bundle': r'C:\\Users\\ROCKRAM\\Downloads\\secure-connect-sample.zip'\n",
    "# }\n",
    "# auth_provider = PlainTextAuthProvider('WZnAUhYtZZCrGJbMRAsWaNUO', 'AoGWhtEbRLx89e+QwIa0qUd,y_AAdyl_8KkJv1Uguc+etLhArJgZg+3_tSkHSdD--s2PMAPoZna7ALlHC2pH_7aI+P9ddSe375qFbKjvFqhabfHW5tY3H5g8wz_tL76A')\n",
    "# cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "# session = cluster.connect()\n",
    "\n",
    "# row = session.execute(\"select release_version from system.local\").one()\n",
    "# if row:\n",
    "#   print(row[0])\n",
    "# else:\n",
    "#   print(\"An error occurred.\")\n",
    "\n",
    "# query = \"SELECT * FROM csv.bmidataset\"\n",
    "# df = pd.DataFrame(list(session.execute(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('bmi data set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_digit(string):\n",
    "    import re\n",
    "    match = re.search(\"\\d\", p(string).stem)\n",
    "    return match.start(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"sample_faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 254 photos \n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "all_files = glob(data_folder+\"/*\")\n",
    "\n",
    "all_jpgs = sorted([img for img in all_files if \".jpg\" in img or \".jpeg\" in img or \"JPG\" in img])\n",
    "\n",
    "print(\"Total {} photos \".format(len(all_jpgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_path = [(p(images).stem[:(get_index_of_digit(p(images).stem))],images) for  images in all_jpgs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pd.DataFrame(id_path,columns=['UID','path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = img_df.merge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ak</td>\n",
       "      <td>sample_faces\\ak1.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Thala Ajith kumar</td>\n",
       "      <td>175.00</td>\n",
       "      <td>80</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ak</td>\n",
       "      <td>sample_faces\\ak10.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Thala Ajith kumar</td>\n",
       "      <td>175.00</td>\n",
       "      <td>80</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak</td>\n",
       "      <td>sample_faces\\ak2.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Thala Ajith kumar</td>\n",
       "      <td>175.00</td>\n",
       "      <td>80</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ak</td>\n",
       "      <td>sample_faces\\ak3.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Thala Ajith kumar</td>\n",
       "      <td>175.00</td>\n",
       "      <td>80</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak</td>\n",
       "      <td>sample_faces\\ak4.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Thala Ajith kumar</td>\n",
       "      <td>175.00</td>\n",
       "      <td>80</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>vikky</td>\n",
       "      <td>sample_faces\\vikky5.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>vicky kaushal</td>\n",
       "      <td>1.83</td>\n",
       "      <td>80</td>\n",
       "      <td>23.888441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>vikky</td>\n",
       "      <td>sample_faces\\vikky6.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>vicky kaushal</td>\n",
       "      <td>1.83</td>\n",
       "      <td>80</td>\n",
       "      <td>23.888441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>vikky</td>\n",
       "      <td>sample_faces\\vikky7.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>vicky kaushal</td>\n",
       "      <td>1.83</td>\n",
       "      <td>80</td>\n",
       "      <td>23.888441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>vikky</td>\n",
       "      <td>sample_faces\\vikky8.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>vicky kaushal</td>\n",
       "      <td>1.83</td>\n",
       "      <td>80</td>\n",
       "      <td>23.888441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>vikky</td>\n",
       "      <td>sample_faces\\vikky9.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>vicky kaushal</td>\n",
       "      <td>1.83</td>\n",
       "      <td>80</td>\n",
       "      <td>23.888441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID                     path  id               name  height  weight  \\\n",
       "0       ak     sample_faces\\ak1.jpg  25  Thala Ajith kumar  175.00      80   \n",
       "1       ak    sample_faces\\ak10.jpg  25  Thala Ajith kumar  175.00      80   \n",
       "2       ak     sample_faces\\ak2.jpg  25  Thala Ajith kumar  175.00      80   \n",
       "3       ak     sample_faces\\ak3.jpg  25  Thala Ajith kumar  175.00      80   \n",
       "4       ak     sample_faces\\ak4.jpg  25  Thala Ajith kumar  175.00      80   \n",
       "..     ...                      ...  ..                ...     ...     ...   \n",
       "249  vikky  sample_faces\\vikky5.jpg   8      vicky kaushal    1.83      80   \n",
       "250  vikky  sample_faces\\vikky6.jpg   8      vicky kaushal    1.83      80   \n",
       "251  vikky  sample_faces\\vikky7.jpg   8      vicky kaushal    1.83      80   \n",
       "252  vikky  sample_faces\\vikky8.jpg   8      vicky kaushal    1.83      80   \n",
       "253  vikky  sample_faces\\vikky9.jpg   8      vicky kaushal    1.83      80   \n",
       "\n",
       "           BMI  \n",
       "0    26.100000  \n",
       "1    26.100000  \n",
       "2    26.100000  \n",
       "3    26.100000  \n",
       "4    26.100000  \n",
       "..         ...  \n",
       "249  23.888441  \n",
       "250  23.888441  \n",
       "251  23.888441  \n",
       "252  23.888441  \n",
       "253  23.888441  \n",
       "\n",
       "[254 rows x 7 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_face_encoding(img_path):\n",
    "#     print(img_path)\n",
    "#     picture_of_me = face_recognition.load_image_file(img_path)\n",
    "#     my_face_encoding = face_recognition.face_encodings(picture_of_me)\n",
    "#     if not my_face_encoding:\n",
    "#         print(\"no face found !!!\")\n",
    "#         return np.zeros(128).tolist()\n",
    "#     return my_face_encoding[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import numpy as np\n",
    "\n",
    "# def get_face_encoding(img_path):\n",
    "#     # read the image file\n",
    "#     img = cv2.imread(img_path)\n",
    "\n",
    "#     # convert the image array to RGB format\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # find all the faces in the image\n",
    "#     face_locations = face_recognition.face_locations(img_rgb)\n",
    "#     if not face_locations:\n",
    "#         print(\"no face found !!!\")\n",
    "#         return np.zeros(128)\n",
    "\n",
    "#     # extract the face encoding\n",
    "#     face_encoding = face_recognition.face_encodings(img_rgb, face_locations)[0]\n",
    "#     return face_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_encoding(image_path):\n",
    "    print(image_path)\n",
    "    picture_of_me = face_recognition.load_image_file(image_path)\n",
    "    my_face_encoding = face_recognition.face_encodings(picture_of_me)\n",
    "    if not my_face_encoding:\n",
    "        print(\"no face found !!!\")\n",
    "        return np.zeros(128).tolist()\n",
    "    return my_face_encoding[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_faces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_faces\\ak1.jpg\n",
      "sample_faces\\ak10.jpg\n",
      "sample_faces\\ak2.jpg\n",
      "sample_faces\\ak3.jpg\n",
      "sample_faces\\ak4.jpg\n",
      "no face found !!!\n",
      "sample_faces\\ak5.jpg\n",
      "sample_faces\\ak6.jpg\n",
      "sample_faces\\ak7.jpg\n",
      "no face found !!!\n",
      "sample_faces\\ak8.jpg\n",
      "sample_faces\\ak9.jpg\n",
      "no face found !!!\n",
      "sample_faces\\akshay1.jpeg\n",
      "sample_faces\\akshay10.jpg\n",
      "sample_faces\\akshay11.jpg\n",
      "sample_faces\\akshay12.jpg\n",
      "sample_faces\\akshay13.jpg\n",
      "sample_faces\\akshay14.jpg\n",
      "sample_faces\\akshay15.jpg\n",
      "sample_faces\\akshay16.jpg\n",
      "sample_faces\\akshay17.jpg\n",
      "sample_faces\\akshay18.jpg\n",
      "sample_faces\\akshay19.jpg\n",
      "sample_faces\\akshay2.jpeg\n",
      "no face found !!!\n",
      "sample_faces\\akshay20.jpg\n",
      "sample_faces\\akshay3.jpg\n",
      "sample_faces\\akshay4.jpg\n",
      "sample_faces\\akshay5.jpg\n",
      "sample_faces\\akshay6.jpg\n",
      "sample_faces\\akshay7.jpg\n",
      "sample_faces\\akshay8.jpg\n",
      "sample_faces\\akshay9.jpg\n",
      "sample_faces\\amir1.jpg\n",
      "sample_faces\\amir10.jpg\n",
      "sample_faces\\amir11.jpg\n",
      "sample_faces\\amir12.jpg\n",
      "sample_faces\\amir13.jpg\n",
      "sample_faces\\amir14.jpeg\n",
      "sample_faces\\amir15.jpg\n",
      "sample_faces\\amir2.jpg\n",
      "sample_faces\\amir3.jpg\n",
      "sample_faces\\amir4.jpeg\n",
      "no face found !!!\n",
      "sample_faces\\amir5.jpg\n",
      "sample_faces\\amir7.jpeg\n",
      "sample_faces\\amir8.jpg\n",
      "sample_faces\\amir9.jpg\n",
      "sample_faces\\anupam2.jpg\n",
      "sample_faces\\anupam3.jpg\n",
      "sample_faces\\anupam4.jpg\n",
      "sample_faces\\anupam5.jpg\n",
      "sample_faces\\anupam6.jpg\n",
      "sample_faces\\anupam7.jpeg\n",
      "sample_faces\\anupam8.jpg\n",
      "sample_faces\\anurag1.jpg\n",
      "sample_faces\\anurag2.jpg\n",
      "sample_faces\\anurag3.jpg\n",
      "sample_faces\\anurag4.jpg\n",
      "sample_faces\\anurag5.jpg\n",
      "sample_faces\\arshad1.jpg\n",
      "sample_faces\\arshad10.jpg\n",
      "sample_faces\\arshad11.jpg\n",
      "sample_faces\\arshad12.jpeg\n",
      "sample_faces\\arshad13.jpg\n",
      "sample_faces\\arshad14.jpg\n",
      "sample_faces\\arshad15.jpg\n",
      "sample_faces\\arshad16.jpg\n",
      "sample_faces\\arshad2.jpg\n",
      "sample_faces\\arshad3.jpeg\n",
      "sample_faces\\arshad4.jpg\n",
      "sample_faces\\arshad5.jpg\n",
      "sample_faces\\arshad6.jpg\n",
      "sample_faces\\arshad7.jpeg\n",
      "sample_faces\\arshad8.jpeg\n",
      "sample_faces\\arshad9.jpg\n",
      "sample_faces\\ayushman1.jpg\n",
      "sample_faces\\ayushman2.jpeg\n",
      "sample_faces\\ayushman3.JPG\n",
      "sample_faces\\ayushman4.jpg\n",
      "sample_faces\\ayushman5.jpg\n",
      "sample_faces\\ja1.jpg\n",
      "sample_faces\\ja10.jpg\n",
      "sample_faces\\ja11.jpg\n",
      "sample_faces\\ja12.jpg\n",
      "sample_faces\\ja13.jpeg\n",
      "sample_faces\\ja14.jpg\n",
      "sample_faces\\ja15.jpg\n",
      "sample_faces\\ja2.jpg\n",
      "sample_faces\\ja3.jpg\n",
      "sample_faces\\ja4.jpg\n",
      "sample_faces\\ja5.jpg\n",
      "sample_faces\\ja6.jpg\n",
      "sample_faces\\ja7.jpg\n",
      "sample_faces\\ja8.jpg\n",
      "sample_faces\\ja9.jpg\n",
      "sample_faces\\kalki1.jpg\n",
      "sample_faces\\kalki10.jpg\n",
      "sample_faces\\kalki11.jpg\n",
      "sample_faces\\kalki12.jpg\n",
      "sample_faces\\kalki13.jpeg\n",
      "sample_faces\\kalki14.jpg\n",
      "sample_faces\\kalki15.jpg\n",
      "sample_faces\\kalki2.jpg\n",
      "sample_faces\\kalki3.jpeg\n",
      "sample_faces\\kalki4.jpg\n",
      "sample_faces\\kalki5.jpg\n",
      "sample_faces\\kalki6.jpg\n",
      "sample_faces\\kalki7.jpg\n",
      "sample_faces\\kalki8.jpg\n",
      "sample_faces\\kalki9.jpg\n",
      "sample_faces\\kirron1.jpg\n",
      "sample_faces\\kirron10.jpg\n",
      "sample_faces\\kirron2.jpg\n",
      "sample_faces\\kirron3.jpg\n",
      "sample_faces\\kirron4.jpg\n",
      "sample_faces\\kirron5.jpg\n",
      "sample_faces\\kirron6.jpg\n",
      "sample_faces\\kirron7.jpg\n",
      "sample_faces\\kirron8.jpg\n",
      "sample_faces\\kirron9.jpeg\n",
      "sample_faces\\manoj1.jpg\n",
      "sample_faces\\manoj2.jpeg\n",
      "sample_faces\\manoj3.jpg\n",
      "sample_faces\\manoj4.jpg\n",
      "sample_faces\\manoj5.JPG\n",
      "sample_faces\\nawaz1.jpg\n",
      "sample_faces\\nawaz2.jpg\n",
      "sample_faces\\nawaz3.jpg\n",
      "sample_faces\\nawaz4.jpg\n",
      "sample_faces\\pankaj1.jpg\n",
      "sample_faces\\pankaj2.jpg\n",
      "sample_faces\\pankaj3.jpg\n",
      "sample_faces\\pankaj5.jpg\n",
      "sample_faces\\pankaj6.jpg\n",
      "sample_faces\\radhika1.jpg\n",
      "sample_faces\\radhika10.jpg\n",
      "sample_faces\\radhika11.jpg\n",
      "sample_faces\\radhika12.jpg\n",
      "sample_faces\\radhika13.jpg\n",
      "sample_faces\\radhika14.jpg\n",
      "sample_faces\\radhika15.jpg\n",
      "sample_faces\\radhika2.jpeg\n",
      "sample_faces\\radhika3.jpg\n",
      "sample_faces\\radhika4.jpg\n",
      "sample_faces\\radhika5.jpg\n",
      "sample_faces\\radhika6.jpg\n",
      "sample_faces\\radhika7.jpg\n",
      "sample_faces\\radhika8.jpg\n",
      "sample_faces\\radhika9.jpg\n",
      "sample_faces\\rajkumar1.jpg\n",
      "sample_faces\\rajkumar2.jpg\n",
      "sample_faces\\rajkumar3.jpg\n",
      "sample_faces\\rajkumar4.jpg\n",
      "sample_faces\\rajkumar5.jpg\n",
      "sample_faces\\ratna1.jpeg\n",
      "sample_faces\\ratna2.jpg\n",
      "sample_faces\\ratna3.jpg\n",
      "sample_faces\\ratna4.JPG\n",
      "sample_faces\\ratna5.jpg\n",
      "sample_faces\\ratna6.jpg\n",
      "sample_faces\\richa2.jpg\n",
      "sample_faces\\richa3.JPG\n",
      "sample_faces\\richa4.jpg\n",
      "sample_faces\\richa5.jpg\n",
      "sample_faces\\rockram1.jpg\n",
      "sample_faces\\rockram2.jpg\n",
      "sample_faces\\rockram3.jpg\n",
      "sample_faces\\rockram4.jpg\n",
      "sample_faces\\rockram5.jpg\n",
      "sample_faces\\rockram6.jpg\n",
      "sample_faces\\rockram7.jpg\n",
      "sample_faces\\rockram8.jpg\n",
      "sample_faces\\salman1.jpg\n",
      "sample_faces\\salman10.jpg\n",
      "sample_faces\\salman11.jpg\n",
      "sample_faces\\salman12.jpg\n",
      "sample_faces\\salman13.jpg\n",
      "sample_faces\\salman14.jpg\n",
      "sample_faces\\salman15.jpg\n",
      "sample_faces\\salman16.jpg\n",
      "sample_faces\\salman17.jpg\n",
      "sample_faces\\salman18.jpg\n",
      "sample_faces\\salman19.jpg\n",
      "sample_faces\\salman2.jpg\n",
      "sample_faces\\salman20.jpg\n",
      "sample_faces\\salman3.jpg\n",
      "sample_faces\\salman4.jpg\n",
      "sample_faces\\salman5.jpeg\n",
      "sample_faces\\salman6.jpg\n",
      "sample_faces\\salman7.jpg\n",
      "sample_faces\\salman8.jpg\n",
      "sample_faces\\salman9.jpg\n",
      "sample_faces\\srk1.jpg\n",
      "sample_faces\\srk10.jpeg\n",
      "sample_faces\\srk11.jpg\n",
      "sample_faces\\srk12.jpg\n",
      "sample_faces\\srk13.jpg\n",
      "sample_faces\\srk14.jpg\n",
      "sample_faces\\srk15.jpg\n",
      "sample_faces\\srk16.jpg\n",
      "sample_faces\\srk17.jpg\n",
      "sample_faces\\srk18.jpg\n",
      "sample_faces\\srk19.jpg\n",
      "sample_faces\\srk2.jpg\n",
      "sample_faces\\srk3.jpeg\n",
      "no face found !!!\n",
      "sample_faces\\srk4.jpg\n",
      "sample_faces\\srk5.jpg\n",
      "sample_faces\\srk6.jpg\n",
      "sample_faces\\srk7.jpg\n",
      "sample_faces\\srk8.jpg\n",
      "sample_faces\\srk9.jpg\n",
      "sample_faces\\supriya1.jpg\n",
      "sample_faces\\supriya2.jpg\n",
      "sample_faces\\supriya3.jpg\n",
      "sample_faces\\supriya4.jpg\n",
      "sample_faces\\supriya5.jpg\n",
      "sample_faces\\supriya6.jpg\n",
      "sample_faces\\tiger1.jpg\n",
      "sample_faces\\tiger2.jpg\n",
      "sample_faces\\tiger4.jpg\n",
      "sample_faces\\tiger5.jpg\n",
      "sample_faces\\tiger6.jpg\n",
      "sample_faces\\varun1.jpg\n",
      "sample_faces\\varun2.jpg\n",
      "sample_faces\\varun3.jpg\n",
      "sample_faces\\varun4.jpeg\n",
      "sample_faces\\varun6.jpeg\n",
      "sample_faces\\vijay1.jpg\n",
      "sample_faces\\vijay10.jpg\n",
      "sample_faces\\vijay2.jpg\n",
      "sample_faces\\vijay3.jpg\n",
      "sample_faces\\vijay4.jpg\n",
      "sample_faces\\vijay5.jpg\n",
      "sample_faces\\vijay6.jpg\n",
      "sample_faces\\vijay7.jpg\n",
      "sample_faces\\vijay8.jpg\n",
      "sample_faces\\vijay9.jpg\n",
      "sample_faces\\vikky1.jpg\n",
      "sample_faces\\vikky10.jpg\n",
      "sample_faces\\vikky11.jpg\n",
      "sample_faces\\vikky12.jpg\n",
      "sample_faces\\vikky13.jpg\n",
      "sample_faces\\vikky14.jpg\n",
      "sample_faces\\vikky15.jpg\n",
      "sample_faces\\vikky16.jpg\n",
      "sample_faces\\vikky17.jpg\n",
      "sample_faces\\vikky18.jpg\n",
      "sample_faces\\vikky19.jpg\n",
      "sample_faces\\vikky2.jpg\n",
      "sample_faces\\vikky20.jpg\n",
      "sample_faces\\vikky3.jpg\n",
      "sample_faces\\vikky4.jpg\n",
      "sample_faces\\vikky5.jpg\n",
      "sample_faces\\vikky6.jpg\n",
      "sample_faces\\vikky7.jpg\n",
      "sample_faces\\vikky8.jpg\n",
      "sample_faces\\vikky9.jpg\n"
     ]
    }
   ],
   "source": [
    "for images in data_df.path:\n",
    "    face_enc = get_face_encoding(images)\n",
    "    tot_faces.append(face_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(tot_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_height = data_df.height.values\n",
    "y_weight = data_df.weight.values\n",
    "y_BMI = data_df.BMI.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_height_train, y_height_test, y_weight_train, y_weight_test ,y_BMI_train, y_BMI_test = train_test_split(X, y_height,y_weight,y_BMI, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the data Type into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_height_train=y_height_train.astype(float)\n",
    "y_height_test=y_height_test.astype(float)\n",
    "y_weight_train=y_weight_train.astype(float)\n",
    "y_weight_test=y_weight_test.astype(float)\n",
    "y_BMI_train=y_BMI_train.astype(float)\n",
    "y_BMI_test=y_BMI_test.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the shape of the Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing height model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 43ms/step - loss: 1.2672 - mae: 0.5980\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1606 - mae: 0.6070\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0915 - mae: 0.5826\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0994 - mae: 0.5439\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.2135 - mae: 0.4859\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1992 - mae: 0.5171\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.0972 - mae: 0.5464\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.1366 - mae: 0.5663\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.1445 - mae: 0.5613\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0927 - mae: 0.5470\n",
      "2/2 [==============================] - 2s 18ms/step - loss: 0.7319 - mae: 0.3531\n",
      "loss of Height: 0.731899619102478\n",
      "mae of Height: 0.3531155586242676\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model_height = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5)\n",
    "])\n",
    "\n",
    "model_height.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_height.fit(X_train, np.log(y_height_train), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss_height_cnn,test_height_accuray = model_height.evaluate(X_test, np.log(y_height_test))\n",
    "\n",
    "#printing the metrics\n",
    "print('loss of Height:', test_loss_height_cnn)\n",
    "print('mae of Height:', test_height_accuray)\n",
    "\n",
    "#saving the model\n",
    "model_height.save('height_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing weight model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 84ms/step - loss: 13.3965 - mae: 3.6208\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 2.5016 - mae: 1.4212\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.8856 - mae: 0.7662\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 1.1568 - mae: 0.9942\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.3775 - mae: 0.4484\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.3817 - mae: 0.4455\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.3211 - mae: 0.4038\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 82ms/step - loss: 0.2207 - mae: 0.2813\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.2138 - mae: 0.2625\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.1986 - mae: 0.2560\n",
      "2/2 [==============================] - 1s 23ms/step - loss: 0.2288 - mae: 0.2111\n",
      "loss of weight: 0.22877739369869232\n",
      "mae of weight: 0.21105632185935974\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model_weight = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='relu')\n",
    "    ])\n",
    "model_weight.compile(loss='mse', optimizer='adam',metrics=['mae'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_weight.fit(X_train, np.log(y_weight_train), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss_weight_cnn,test_weight_accuray = model_weight.evaluate(X_test, np.log(y_weight_test))\n",
    "\n",
    "#printing the metrics\n",
    "print('loss of weight:', test_loss_weight_cnn)\n",
    "print('mae of weight:', test_weight_accuray)\n",
    "\n",
    "#saving the model\n",
    "model_weight.save('weight_model.h5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing BMI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 4s 37ms/step - loss: 7.4268 - mae: 2.6965\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.2128 - mae: 0.9515\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8786 - mae: 0.7865\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4658 - mae: 0.5877\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.3051 - mae: 0.4161\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.2411 - mae: 0.3800\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.1518 - mae: 0.2191\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1696 - mae: 0.2759\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1230 - mae: 0.1700\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1224 - mae: 0.1730\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.1491 - mae: 0.1463\n",
      "loss of BMI: 0.14909550547599792\n",
      "mae of BMI: 0.14634348452091217\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model_BMI = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='relu')\n",
    "])\n",
    "model_BMI.compile(loss='mse', optimizer='adam',metrics=['mae'])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_BMI.fit(X_train, np.log(y_BMI_train), epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss_BMI_cnn,test_BMI_accuray = model_BMI.evaluate(X_test, np.log(y_BMI_test))\n",
    "\n",
    "#printing the metrics\n",
    "print('loss of BMI:', test_loss_BMI_cnn)\n",
    "print('mae of BMI:', test_BMI_accuray)\n",
    "\n",
    "#saving the model\n",
    "model_BMI.save('BMI_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#;oad the models\n",
    "\n",
    "height_model = tf.keras.models.load_model('height_model.h5')\n",
    "weight_model = tf.keras.models.load_model('weight_model.h5')\n",
    "BMI_model = tf.keras.models.load_model('BMI_model.h5')\n",
    "\n",
    "def predict_heit_width_BMI(input_img,height_model,weight_model,BMI_model):\n",
    "    test_array = np.expand_dims(np.array(get_face_encoding(input_img)),axis=0)\n",
    "    height = np.ndarray.item(np.exp(height_model.predict(test_array)))\n",
    "    weight = np.ndarray.item(np.exp(weight_model.predict(test_array)))\n",
    "    bmi = np.ndarray.item(np.exp(BMI_model.predict(test_array)))\n",
    "    return {'height':height,\"weight\":weight,\"bmi\":bmi}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for code level deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = r\"C:\\Users\\ROCKRAM\\Downloads\\Face-to-height-weight-BMI-estimation--master\\Face-to-height-weight-BMI-estimation--master\\bmi project\\test_faces\\amit2.jpg\"\n",
    "Image(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROCKRAM\\Downloads\\Face-to-height-weight-BMI-estimation--master\\Face-to-height-weight-BMI-estimation--master\\bmi project\\test_faces\\amit2.jpg\n"
     ]
    }
   ],
   "source": [
    "print((input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROCKRAM\\Downloads\\Face-to-height-weight-BMI-estimation--master\\Face-to-height-weight-BMI-estimation--master\\bmi project\\test_faces\\amit2.jpg\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'height': 1.319846749305725,\n",
       " 'weight': 68.66764831542969,\n",
       " 'bmi': 23.72263526916504}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_heit_width_BMI(input_img,height_model,weight_model,BMI_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating GUI using tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROCKRAM\\AppData\\Local\\Temp\\ipykernel_11808\\290438976.py:44: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((300, 300), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captured_image.jpg\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "captured_image.jpg\n",
      "no face found !!!\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define the function to predict height, weight, and BMI\n",
    "def predict_heit_width_BMI(input_img,height_model,weight_model,BMI_model):\n",
    "    test_array = np.expand_dims(np.array(get_face_encoding(input_img)),axis=0)\n",
    "    height = np.ndarray.item(np.exp(height_model.predict(test_array)))\n",
    "    weight = np.ndarray.item(np.exp(weight_model.predict(test_array)))\n",
    "    bmi = np.ndarray.item(np.exp(BMI_model.predict(test_array)))\n",
    "    return {'height':height,\"weight\":weight,\"bmi\":bmi}\n",
    "\n",
    "# Define a function to get the file path of the selected image\n",
    "def browse_file():\n",
    "    global photo # Add this line to access the global variable\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Open the selected image and display it in the UI\n",
    "        image = Image.open(file_path)\n",
    "        image = image.resize((300, 300), Image.ANTIALIAS)\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        canvas.itemconfigure(image_id, image=photo)\n",
    "        canvas.image = photo\n",
    "\n",
    "        # Call the predict_heit_width_BMI() function and display the results in the UI\n",
    "        result = predict_heit_width_BMI(file_path, height_model, weight_model, BMI_model)\n",
    "        result_label.config(text=f\"Height: {result['height']:.2f}\\nWeight: {result['weight']:.2f}\\nBMI: {result['bmi']:.2f}\")\n",
    "\n",
    "def capture_image():\n",
    "    global photo # Add this line to access the global variable\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # Save the captured image and display it in the UI\n",
    "                cv2.imwrite('captured_image.jpg', frame)\n",
    "                image = Image.open('captured_image.jpg')\n",
    "                image = image.resize((300, 300), Image.ANTIALIAS)\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "                canvas.itemconfigure(image_id, image=photo)\n",
    "                canvas.image = photo\n",
    "\n",
    "                # Call the predict_heit_width_BMI() function and display the results in the UI\n",
    "                result = predict_heit_width_BMI('captured_image.jpg', height_model, weight_model, BMI_model)\n",
    "                result_label.config(text=f\"Height: {result['height']:.2f}\\nWeight: {result['weight']:.2f}\\nBMI: {result['bmi']:.2f}\")\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define a function to clear the selected image and results\n",
    "def clear_display():\n",
    "    global photo # Add this line to access the global variable\n",
    "    canvas.delete(image_id)\n",
    "    result_label.config(text=\"\")\n",
    "    photo = None # Set the global variable to None to allow the PhotoImage object to be garbage collected\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Predict Height, Weight, and BMI\")\n",
    "\n",
    "# Create the canvas to display the image\n",
    "canvas = tk.Canvas(root, width=300, height=300)\n",
    "canvas.pack()\n",
    "\n",
    "# Create a label to display the results\n",
    "result_label = tk.Label(root, font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Create a label to display the results\n",
    "result_label = tk.Label(root, font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Create a frame for the buttons\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(pady=10)\n",
    "\n",
    "# Create a button to browse for an image\n",
    "browse_button = tk.Button(button_frame, text=\"Browse\", command=browse_file)\n",
    "browse_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Create a button to capture image from the camera\n",
    "capture_button = tk.Button(button_frame, text=\"Capture\", command=capture_image)\n",
    "capture_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Create a button to clear the displayed image and results\n",
    "clear_button = tk.Button(button_frame, text=\"Clear\", command=clear_display)\n",
    "clear_button.pack(side=tk.RIGHT, padx=10)\n",
    "\n",
    "# Initialize the image_id variable\n",
    "image_id = canvas.create_image((0, 0), anchor='nw')\n",
    "\n",
    "# Load the height, weight, and BMI models\n",
    "height_model = tf.keras.models.load_model('height_model.h5')\n",
    "weight_model = tf.keras.models.load_model('weight_model.h5')\n",
    "BMI_model = tf.keras.models.load_model('BMI_model.h5')\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3420ed2c65300ffc1d71199033e9176e0c26ff8ced7474b2f05f6e440a26153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
